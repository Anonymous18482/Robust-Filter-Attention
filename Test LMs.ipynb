{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6d514e",
   "metadata": {},
   "source": [
    "## Robust Filter Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045d0d7",
   "metadata": {},
   "source": [
    "### Testing trained language models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302ab5d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import patches\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import transformers\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm # Loading bar\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf03acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import complex_matmul, apply_interleaved_rope\n",
    "from utils import count_parameters, get_layers, seed_everything\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isotropic_rfa import get_safe_exp_tot, compute_covariance_matrix, compute_covariance_matrix_LHopital\n",
    "from isotropic_rfa import compute_covariance_matrix_spectral_full, compute_covariance_matrix_residual_diffusion\n",
    "from isotropic_rfa import compute_exp_kernel_isotropic, compute_residual_norm_isotropic\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resolve_multihead_dims, autoregressive_sample\n",
    "from model import init_complexlinear, init_complex_matrix, initialize_linear_layers\n",
    "from model import init_rope, init_decay_per_head, init_linear_bias_slopes\n",
    "from model import apply_weight_masks\n",
    "from model import ComplexLinearLayer, ComplexLinearHermitianLayer, ComplextoRealLinearLayer\n",
    "from model import ComplexRMSNorm\n",
    "from model import MultiHeadAttentionLayer, MultiheadIsotropicRFA\n",
    "from model import TransformerBlock, TransformerNetwork\n",
    "from model import SelfAttentionBlock, RFA_Block\n",
    "from model import RFATransformerBlock, RFATransformerNetwork\n",
    "from model import LanguageModel\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63456b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_trajectory, compute_state_matrix, plot_state_matrix, visualize_results\n",
    "from visualization import visualize_results_attn, _get_visual_modules, visualize_rfa_lm\n",
    "from visualization import plot_training_progress_lm\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import single_epoch_rfa_lm, single_epoch_standard_lm\n",
    "from training import hook_fn\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf79216",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('DA')\n",
    "parser.add_argument('--gpu', type=int, default=0) # (Default: 0)\n",
    "args = parser.parse_args(args=[])\n",
    "args.device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "print(args.device)\n",
    "    \n",
    "seed_everything(seed=2025) # Set random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2b2a1",
   "metadata": {},
   "source": [
    "### Plot validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data histories\n",
    "\n",
    "try:\n",
    "    root_path = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    root_path = os.getcwd()\n",
    "\n",
    "# search_base = os.path.join(root_path, 'saved_models', 'wikitext_103')\n",
    "search_base = Path(os.path.join(root_path, 'saved_models', 'main_models'))\n",
    "results_data = {}\n",
    "\n",
    "for file_path in search_base.rglob(\"*_epoch_15.pt\"):\n",
    "    folder_name = file_path.parent.name\n",
    "    parts = folder_name.split(\"__\")\n",
    "    aid = parts[1] if len(parts) > 1 else folder_name\n",
    "\n",
    "    print(f\"Loading {aid} from: {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(file_path, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        # 1. Capture the full history dict here\n",
    "        full_history = checkpoint.get('history', {})\n",
    "        \n",
    "        if full_history:\n",
    "            # 2. Add 'full_history' to the stored data\n",
    "            results_data[aid] = {\n",
    "                'history': full_history.get('val_ppl', []),\n",
    "                'full_history': full_history, \n",
    "                'final_ppl': full_history.get('val_ppl', [0])[-1],\n",
    "                'state_dict': checkpoint.get('model_state_dict', {})\n",
    "            }\n",
    "        \n",
    "        del checkpoint\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {aid}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "start_epoch = 5  # Set this to > 1 to zoom into the settle phase\n",
    "save_pdf = True\n",
    "\n",
    "if not results_data:\n",
    "    print(\"Error: No data loaded.\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Sort IDs (M0, M1, M2, M7...)\n",
    "    sorted_keys = sorted(results_data.keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 99)\n",
    "    \n",
    "    for aid in sorted_keys:\n",
    "        y_full = results_data[aid]['history']\n",
    "        \n",
    "        # Slice the data based on start_epoch (Python is 0-indexed)\n",
    "        # We use max(0, start_epoch - 1) to handle the 1-based input\n",
    "        idx = max(0, start_epoch - 1)\n",
    "        y_sliced = y_full[idx:]\n",
    "        x_axis = range(idx + 1, len(y_full) + 1)\n",
    "        \n",
    "        if len(y_sliced) > 0:\n",
    "            plt.plot(x_axis, y_sliced, \n",
    "                     label=f\"{aid} (Final: {results_data[aid]['final_ppl']:.2f})\", \n",
    "                     linewidth=2, marker='o', markersize=4)\n",
    "\n",
    "    # Use standard linear scale for the zoom to maximize visual separation\n",
    "    plt.yscale('linear') \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Perplexity')\n",
    "#     plt.title(f'RFA Convergence Detail (Epoch {start_epoch} onwards)')\n",
    "    \n",
    "    # Move legend to the side to keep the plot area clean\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_pdf:\n",
    "        plt.savefig(f'rfa_ablation_zoom_ep{start_epoch}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_data:\n",
    "    print(\"Error: No data loaded.\")\n",
    "else:\n",
    "    # --- Colorblind-Friendly Palette (Okabe-Ito) ---\n",
    "    cb_colors = ['#0072B2', '#E69F00', '#CC79A7', '#56B4E9', '#F0E442', '#000000', '#D55E00', '#999999']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 1. Sort by final loss (Highest PPL first)\n",
    "    sorted_aids = sorted(results_data.keys(), \n",
    "                         key=lambda aid: results_data[aid]['final_ppl'], \n",
    "                         reverse=True)\n",
    "    \n",
    "    # 2. Define the exact names in the order of the sorted data\n",
    "    manual_names = ['ALiBi (B2)', 'RoPE (B1)', 'RFA (M1)', 'SC-RFA (M2)']\n",
    "\n",
    "    for i, aid in enumerate(sorted_aids):\n",
    "        y_full = results_data[aid]['history']\n",
    "        \n",
    "        # Slicing logic\n",
    "        idx = max(0, start_epoch - 1)\n",
    "        y_sliced = y_full[idx:]\n",
    "        x_axis = range(idx + 1, len(y_full) + 1)\n",
    "        \n",
    "        label_name = manual_names[i] if i < len(manual_names) else aid\n",
    "        color = cb_colors[i % len(cb_colors)]\n",
    "        \n",
    "        if len(y_sliced) > 0:\n",
    "            plt.plot(x_axis, y_sliced, \n",
    "                     label=f\"{label_name} ({results_data[aid]['final_ppl']:.2f})\", \n",
    "                     color=color,\n",
    "                     linewidth=2.5, # Slightly thicker lines for visibility\n",
    "                     marker='o', \n",
    "                     markersize=5)\n",
    "\n",
    "    # --- Formatting for High Readability ---\n",
    "    plt.yscale('linear') \n",
    "    \n",
    "    # Increased font sizes for the axes labels\n",
    "    plt.xlabel('Epoch', fontsize=16, fontweight='medium')\n",
    "    plt.ylabel('Validation Perplexity', fontsize=16, fontweight='medium')\n",
    "    \n",
    "    # Increased font sizes for the tick numbers (1, 2, 3... and 10, 20, 30...)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # --- Balanced Large Legend ---\n",
    "    plt.legend(\n",
    "        loc='upper right', \n",
    "        framealpha=0.9, \n",
    "        borderaxespad=1.2, \n",
    "        fontsize=14,        # Matches tick sizes\n",
    "        labelspacing=0.4,   # Tight but readable\n",
    "        handletextpad=0.5\n",
    "    )\n",
    "    \n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.15)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_pdf:\n",
    "        plt.savefig(f'rfa_ablation_zoom_ep{start_epoch}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25680cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rope: yellow circle\n",
    "# alibi: dark blue diamond\n",
    "# rfa: pink square\n",
    "# sc_rfa: light blue triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "\n",
    "if not results_data:\n",
    "    print(\"Error: No data loaded.\")\n",
    "else:\n",
    "    # --- Colorblind-Friendly Palette (Okabe-Ito) ---\n",
    "    cb_colors = ['#0072B2', '#E69F00', '#CC79A7', '#56B4E9', '#F0E442', '#000000', '#D55E00', '#999999']\n",
    "    \n",
    "    # --- Professional Style Assets ---\n",
    "    line_styles = ['--', '-', '-.', ':']\n",
    "    markers = ['D', 'o', 's', '^']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 1. Sort by final loss (Highest PPL first)\n",
    "    sorted_aids = sorted(results_data.keys(), \n",
    "                         key=lambda aid: results_data[aid]['final_ppl'], \n",
    "                         reverse=True)\n",
    "    \n",
    "    # 2. Define the exact names in the order of the sorted data\n",
    "    manual_names = ['ALiBi (B2)', 'RoPE (B1)', 'RFA (M1)', 'SC-RFA (M2)']\n",
    "\n",
    "    for i, aid in enumerate(sorted_aids):\n",
    "        y_full = results_data[aid]['history']\n",
    "        \n",
    "        # Slicing logic\n",
    "        idx = max(0, start_epoch - 1)\n",
    "        y_sliced = y_full[idx:]\n",
    "        x_axis = range(idx + 1, len(y_full) + 1)\n",
    "        \n",
    "        label_name = manual_names[i] if i < len(manual_names) else aid\n",
    "        \n",
    "#         Apply the unique style combination\n",
    "        plt.plot(x_axis, y_sliced, \n",
    "                 label=f\"{label_name} ({results_data[aid]['final_ppl']:.2f})\", \n",
    "                 color=cb_colors[i % len(cb_colors)],\n",
    "                 linestyle=line_styles[i % len(line_styles)],\n",
    "                 marker=markers[i % len(markers)],\n",
    "                 linewidth=2.0, \n",
    "                 markersize=6,\n",
    "                 markeredgewidth=1.5\n",
    ")\n",
    "    # --- Formatting for High Readability ---\n",
    "    plt.yscale('linear') \n",
    "    plt.xlabel('Epoch', fontsize=16, fontweight='medium')\n",
    "    plt.ylabel('Validation Perplexity', fontsize=16, fontweight='medium')\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # Clean up the spines (Standard for modern journals)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # --- Balanced Large Legend ---\n",
    "    plt.legend(\n",
    "        loc='upper right', \n",
    "        framealpha=0.9, \n",
    "        borderaxespad=1.2, \n",
    "        fontsize=14, \n",
    "        labelspacing=0.4, \n",
    "        handletextpad=0.5\n",
    "    )\n",
    "    \n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_pdf:\n",
    "        # Saving as PDF is crucial for vector graphics in LaTeX\n",
    "        plt.savefig(f'rfa_convergence_professional_ep{start_epoch}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_generalization_gaps(results_data, start_epoch=1):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Sort IDs (B1, M1, M2, M7...)\n",
    "    sorted_keys = sorted(results_data.keys(), key=lambda x: int(x[1:]) if x[1:].isdigit() else 99)\n",
    "    \n",
    "    for aid in sorted_keys:\n",
    "        # Access the 'full_history' dict we saved during loading\n",
    "        h = results_data[aid].get('full_history', {})\n",
    "        \n",
    "        if not h:\n",
    "            continue\n",
    "            \n",
    "        val_loss = np.array(h.get('val_loss', []))\n",
    "        train_loss_raw = np.array(h.get('loss', [])) \n",
    "        \n",
    "        if len(val_loss) == 0 or len(train_loss_raw) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 2. Average training batches into epoch-level losses\n",
    "        num_epochs = len(val_loss)\n",
    "        batches_per_epoch = len(train_loss_raw) // num_epochs\n",
    "        \n",
    "        train_loss_epoch = []\n",
    "        for i in range(num_epochs):\n",
    "            start_idx = i * batches_per_epoch\n",
    "            # Capture remainders in the final epoch\n",
    "            end_idx = (i + 1) * batches_per_epoch if i < num_epochs - 1 else len(train_loss_raw)\n",
    "            train_loss_epoch.append(np.mean(train_loss_raw[start_idx:end_idx]))\n",
    "        \n",
    "        train_loss_epoch = np.array(train_loss_epoch)\n",
    "        \n",
    "        # 3. Calculate Gap\n",
    "        gap = val_loss - train_loss_epoch\n",
    "        \n",
    "        # 4. Slice for start_epoch and Plot\n",
    "        idx = max(0, start_epoch - 1)\n",
    "        epochs = range(idx + 1, num_epochs + 1)\n",
    "        \n",
    "        plt.plot(epochs, gap[idx:], marker='s', label=f'{aid} Gap', linewidth=2)\n",
    "#         print(gap)\n",
    "\n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.3)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val NLL - Train NLL')\n",
    "    plt.title(f'Generalization Gap Comparison (Epoch {start_epoch}+)')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call this using your results_data dictionary\n",
    "plot_all_generalization_gaps(results_data, start_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_generalization_gaps(results_data, start_epoch=5):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 1. Sort by final gap (Highest Gap first = Worst Generalization)\n",
    "    # We define gap as final val_loss - final train_loss\n",
    "    sorted_aids = sorted(results_data.keys(), \n",
    "                         key=lambda aid: (results_data[aid]['full_history']['val_loss'][-1] - \n",
    "                                          np.mean(results_data[aid]['full_history']['loss'][-100:])), \n",
    "                         reverse=True)\n",
    "\n",
    "    manual_names = ['AliBi (B2)', 'RoPe (B1)', 'RFA (M1)', 'SC-RFA (M2)']\n",
    "\n",
    "    for i, aid in enumerate(sorted_aids):\n",
    "        h = results_data[aid].get('full_history', {})\n",
    "        if not h: continue\n",
    "            \n",
    "        val_loss = np.array(h.get('val_loss', []))\n",
    "        train_loss_raw = np.array(h.get('loss', [])) \n",
    "        \n",
    "        # Calculate epoch-level train loss\n",
    "        num_epochs = len(val_loss)\n",
    "        batches_per_epoch = len(train_loss_raw) // num_epochs\n",
    "        train_loss_epoch = np.array([\n",
    "            np.mean(train_loss_raw[j*batches_per_epoch : (j+1)*batches_per_epoch]) \n",
    "            for j in range(num_epochs)\n",
    "        ])\n",
    "        \n",
    "        # --- THE FIX: Look at the Gap Trend ---\n",
    "        gap = val_loss - train_loss_epoch\n",
    "        \n",
    "        idx = max(0, start_epoch - 1)\n",
    "        epochs = range(idx + 1, num_epochs + 1)\n",
    "        label_name = manual_names[i] if i < len(manual_names) else aid\n",
    "        \n",
    "        plt.plot(epochs, gap[idx:], marker='s', label=f'{label_name}', linewidth=2)\n",
    "\n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.3)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Generalization Gap (Val NLL - Train NLL)')\n",
    "    plt.title(f'Generalization Gap: Structural Regularization (Epoch {start_epoch}+)')\n",
    "    \n",
    "    # Overlay legend top-left (usually gaps grow, so top-left is empty space)\n",
    "    plt.legend(loc='upper left', framealpha=0.8)\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_all_generalization_gaps(results_data, start_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_relative_ppl_gain_vs_m1(results_data, start_epoch=1, save_pdf=False):\n",
    "    if not results_data:\n",
    "        print(\"Error: No data loaded.\")\n",
    "        return\n",
    "\n",
    "    # --- Standardized Style Assets (Matching Plot 1) ---\n",
    "    cb_colors = ['#0072B2', '#E69F00', '#CC79A7', '#56B4E9', '#F0E442', '#000000', '#D55E00', '#999999']\n",
    "    line_styles = ['--', '-', '-.', ':']\n",
    "    markers = ['D', 'o', 's', '^']\n",
    "    \n",
    "    # --- Exact same sorting logic as Plot 1 to keep colors consistent ---\n",
    "    sorted_aids = sorted(results_data.keys(), \n",
    "                         key=lambda aid: results_data[aid]['final_ppl'], \n",
    "                         reverse=True)\n",
    "    manual_names = ['ALiBi (B2)', 'RoPE (B1)', 'RFA (M1)', 'SC-RFA (M2)']\n",
    "\n",
    "    # Identify the baseline (M1) series\n",
    "    # Note: Using M1_power_law as per your snippet logic\n",
    "    if 'M1_power_law' not in results_data:\n",
    "        print(\"M1_power_law data missing.\")\n",
    "        return\n",
    "    m1_ppl = np.array(results_data['M1_power_law']['full_history']['val_ppl'])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i, aid in enumerate(sorted_aids):\n",
    "        # Determine label name based on index to match Plot 1\n",
    "        label_base = manual_names[i] if i < len(manual_names) else aid\n",
    "        \n",
    "        # Skip plotting M1 as a line since it's the 0% axhline, \n",
    "        # but we keep the index 'i' moving to preserve color mapping for others.\n",
    "        if \"RFA (M1)\" in label_base or aid == 'M1_power_law':\n",
    "            continue \n",
    "\n",
    "        h = results_data[aid].get('full_history', {})\n",
    "        current_ppl = np.array(h.get('val_ppl', []))\n",
    "        \n",
    "        if len(current_ppl) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate Percent Difference\n",
    "        pct_diff_ppl = ((current_ppl - m1_ppl) / m1_ppl) * 100\n",
    "        \n",
    "        idx = max(0, start_epoch - 1)\n",
    "        epochs = range(idx + 1, len(pct_diff_ppl) + 1)\n",
    "        \n",
    "        plt.plot(epochs, pct_diff_ppl[idx:], \n",
    "                 label=f\"{label_base} vs M1\", \n",
    "                 color=cb_colors[i % len(cb_colors)],\n",
    "                 linestyle=line_styles[i % len(line_styles)],\n",
    "                 marker=markers[i % len(markers)],\n",
    "                 linewidth=2.0, \n",
    "                 markersize=6,\n",
    "                 markeredgewidth=1.5)\n",
    "\n",
    "    # --- Add the M1 baseline ---\n",
    "    plt.axhline(0, color='black', linestyle='-', linewidth=1.5, label='M1 (RFA) Baseline', alpha=0.6)\n",
    "    \n",
    "    # --- Formatting (Matching Plot 1) ---\n",
    "    plt.xlabel('Epoch', fontsize=16, fontweight='medium')\n",
    "    plt.ylabel('PPL Difference relative to M1 (%)', fontsize=16, fontweight='medium')\n",
    "    plt.ylim(-2.5,5)\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.legend(\n",
    "#         loc='best',\n",
    "        loc='upper right', \n",
    "        framealpha=0.9, \n",
    "        borderaxespad=1.2, \n",
    "        fontsize=13, \n",
    "        labelspacing=0.4\n",
    "    )\n",
    "    \n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_pdf:\n",
    "        plt.savefig(f'rfa_relative_gain_ep{start_epoch}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Execute\n",
    "plot_relative_ppl_gain_vs_m1(results_data, start_epoch=1, save_pdf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30dea6d",
   "metadata": {},
   "source": [
    "B1 vs. M1 (Blue Line): M1 is 1.3% to 2.0% better than the RoPE baseline throughout the entire run.\n",
    "\n",
    "M7 vs. M1 (Green Line): M1 is 1.3% better than the fixed Unitary model. This specifically proves that learning the noise parameters ($\\mu, \\sigma$) provides a measurable performance boost over just having a \"fixed\" physical structure.\n",
    "\n",
    "M2 vs. M1 (Orange Line): M2 is slightly better in raw PPL (below the $0$ line). However, when you look back at the Gap plot, you see that M2 has the highest overfitting. This confirms that M2's lead is \"brittle\"â€”it achieves lower PPL by sacrificing generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2874130",
   "metadata": {},
   "source": [
    "## Below, we load the data and trained models, and test them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82f718",
   "metadata": {},
   "source": [
    "### Load Wikitext-103 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c911bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikitext data files\n",
    "data_files = {\n",
    "    \"train\": \"datasets/wikitext-103/train-*.parquet\",\n",
    "    \"validation\": \"datasets/wikitext-103/validation-*.parquet\",\n",
    "    \"test\": \"datasets/wikitext-103/test-*.parquet\"\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "raw_datasets = load_dataset(\"parquet\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ffece",
   "metadata": {},
   "source": [
    "### Load BabyLM-2025 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11288a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load Wikitext-103 dataset# Define the directory\n",
    "# train_dir = \"datasets/BabyLM_2025/train_100M\"\n",
    "\n",
    "# # Get all .train files in that folder\n",
    "# train_files = glob.glob(os.path.join(train_dir, \"*.train\"))\n",
    "\n",
    "# # Update data_files dictionary\n",
    "# data_files = {\n",
    "#     \"train\": train_files,\n",
    "#     \"validation\": glob.glob(\"datasets/BabyLM_2025/dev/*.dev\"),\n",
    "#     \"test\": glob.glob(\"datasets/BabyLM_2025/test/*.test\")\n",
    "# }\n",
    "\n",
    "# # Load as 'text' since these are raw .txt files\n",
    "# raw_datasets = load_dataset(\"text\", data_files=data_files)\n",
    "\n",
    "# # Now, raw_datasets[\"train\"] will behave as one single, \n",
    "# # giant dataset containing every novel and transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c98505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") \n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\n",
    "    \"./gpt2_tokenizer/\",\n",
    "    local_files_only=True  # This GUARANTEES it won't try to use the internet\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize and Chunk\n",
    "def tokenize_function(examples, tokenizer=None):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    num_proc=4, \n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into blocks\n",
    "\n",
    "def group_texts(examples, block_size):\n",
    "    from itertools import chain\n",
    "    # 1. Flatten all the token lists into one long list (Efficiently)\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    \n",
    "    # 2. Get the total number of tokens\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # 3. Round down to the nearest multiple of block_size\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        \n",
    "    # 4. Chop into fixed-size chunks\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    # 5. Create the labels (same as inputs for Causal LM)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    \n",
    "    return result\n",
    "\n",
    "block_size = 512\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    fn_kwargs={\"block_size\": 512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ea2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out incorrect lengths\n",
    "\n",
    "# Run this for all splits (train, validation, test)\n",
    "lm_datasets = lm_datasets.filter(lambda x: len(x[\"input_ids\"]) == 512)\n",
    "\n",
    "# Verify one last time\n",
    "lengths = [len(x) for x in lm_datasets[\"validation\"][\"input_ids\"]]\n",
    "print(f\"New validation size: {len(lengths)} blocks\")\n",
    "print(f\"Non-512 sequences remaining: {sum(1 for l in lengths if l != 512)}\")\n",
    "\n",
    "\n",
    "# Note: Use \"validation\" or \"test\" depending on which split caused the error\n",
    "check_split = \"validation\" \n",
    "\n",
    "lengths = [len(x) for x in lm_datasets[check_split][\"input_ids\"]]\n",
    "short_sequences = [l for l in lengths if l != 512]\n",
    "\n",
    "print(f\"--- Analysis for {check_split} split ---\")\n",
    "print(f\"Total sequences: {len(lengths)}\")\n",
    "print(f\"Number of non-512 sequences: {len(short_sequences)}\")\n",
    "\n",
    "if short_sequences:\n",
    "    print(f\"Shortest sequence found: {min(short_sequences)}\")\n",
    "    print(f\"Indices of short sequences: {[i for i, l in enumerate(lengths) if l != 512]}\")\n",
    "    \n",
    "    \n",
    "# Note: Use \"validation\" or \"test\" depending on which split caused the error\n",
    "check_split = \"test\" \n",
    "\n",
    "lengths = [len(x) for x in lm_datasets[check_split][\"input_ids\"]]\n",
    "short_sequences = [l for l in lengths if l != 512]\n",
    "\n",
    "print(f\"--- Analysis for {check_split} split ---\")\n",
    "print(f\"Total sequences: {len(lengths)}\")\n",
    "print(f\"Number of non-512 sequences: {len(short_sequences)}\")\n",
    "\n",
    "if short_sequences:\n",
    "    print(f\"Shortest sequence found: {min(short_sequences)}\")\n",
    "    print(f\"Indices of short sequences: {[i for i, l in enumerate(lengths) if l != 512]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a70328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single example\n",
    "sample = lm_datasets[\"train\"][0]\n",
    "\n",
    "print(f\"Dataset size: {len(lm_datasets['train'])} blocks\")\n",
    "print(f\"Sequence Length: {len(sample['input_ids'])}\")\n",
    "print(f\"Features: {lm_datasets['train'].column_names}\")\n",
    "\n",
    "# Verify label alignment (should be identical before the model-side shift)\n",
    "is_aligned = sample['input_ids'] == sample['labels']\n",
    "print(f\"Labels perfectly aligned with inputs: {is_aligned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8876a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the first block\n",
    "decoded_text = tokenizer.decode(sample['input_ids'])\n",
    "\n",
    "print(\"--- SAMPLE DATA START ---\")\n",
    "print(decoded_text[:500]) # Print first 500 characters\n",
    "print(\"--- SAMPLE DATA END ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af68cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample 1000 tokens from the first few blocks\n",
    "# all_tokens = []\n",
    "# for i in range(5):\n",
    "#     all_tokens.extend(lm_datasets[\"train\"][i][\"input_ids\"])\n",
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.hist(all_tokens, bins=100, color='skyblue', edgecolor='black')\n",
    "# plt.title(\"Token ID Distribution (WikiText-103)\")\n",
    "# plt.xlabel(\"Token ID\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.grid(axis='y', alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5241bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm_datasets[\"train\"]\n",
    "# # Dataset({\n",
    "# #     features: ['input_ids', 'attention_mask', 'labels'],\n",
    "# #     num_rows: 229206\n",
    "# # })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e3558",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## MODEL SETTINGS ##\n",
    "####################\n",
    "\n",
    "args.batch_size = 16 # Batch size\n",
    "args.vocab_size = 50257\n",
    "args.d_e = 256\n",
    "args.seq_len = 512\n",
    "args.n_heads = 8\n",
    "args.d_k_total = args.d_e # Total query-key dim across all heads\n",
    "args.d_v_total = args.d_e # Total value dim across all heads\n",
    "# args.num_blocks = 3\n",
    "\n",
    "# args.max_learned_decay = 1.4 # e/2\n",
    "args.max_learned_decay = 5.0\n",
    "args.max_fixed_decay = 5.0 # Can be more aggressive\n",
    "\n",
    "# Limits for clamping exponent\n",
    "args.max_exponent = 0\n",
    "args.min_exponent = -10\n",
    "\n",
    "args.epsilon = 1E-5 # Stability param\n",
    "\n",
    "args.compute_metadata = False # Triggers computing various diagnostics; turned off during training\n",
    "args.compute_pulled_forward_estimates = False # \"Project\" every past state into every future frame; very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72150bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## DEFAULT ABLATION OPTIONS ##\n",
    "##############################\n",
    "args.causal = True\n",
    "args.t_equal = True # Equal time intervals?\n",
    "args.sep_params = False # Use separate params for keys and values?\n",
    "args.lambda_real_zero = False # Zero out real part of eigenvalues?\n",
    "args.use_full_residual_norm = 1 # Use the full |R|^2 metric?\n",
    "args.use_robust_weight = True # Use rational weight rather than softmax\n",
    "args.additive_bias_type = 1 # (Additive bias: 0 for zero; 1 for DLE; 2 for linear)\n",
    "args.multiplicative_bias_type = 1 # (Multiplicative bias: 0 for constant; 1 for DLE; 2 for linear)\n",
    "args.t_shift = None # Default\n",
    "args.learn_t_shift = True\n",
    "if args.learn_t_shift == True:\n",
    "    args.t_shift = None\n",
    "args.learn_rotations = False # Learned rotations (True), or fixed as in RoPE (False)?\n",
    "args.learn_decay = False # Learned decay (True), or fixed (False)?\n",
    "args.rotate_values = True # Rotate/unrotate values?\n",
    "args.zero_process_noise = False # Zero process noise (sigma^2)?\n",
    "args.zero_key_measurement_noise = False # Zero key measurement noise (eta^2)?\n",
    "args.use_total_precision_gate = 1 # Use total-precision gating? (0 = No gate, 1 = precision gate, 2 = learned gate)\n",
    "args.use_inner_residual = False # Include a residual connection BEFORE output projection?\n",
    "args.use_outer_residual = True # Include a residual connection AFTER output projection?\n",
    "args.use_complex_input_norm = 0 # Use complex-valued RMS Norm AFTER input projection for query/key/value (1), complex-valued RMS Norm AFTER input projection only for query/key (2), or None (0)?\n",
    "args.use_complex_output_norm = False # Use complex-valued RMS Norm BEFORE output projection?\n",
    "args.use_real_input_norm = True # Use real-valued RMS Norm BEFORE input projection?\n",
    "args.use_real_output_norm = True # Use real-valued RMS Norm AFTER output projection?\n",
    "args.add_gaussian_noise = False # Add Gaussian noise to final token? (for test-time sampling)\n",
    "args.use_complex_conj_constraint = True # Eigenvalues must appear in complex conjugate pairs to ensure A is real\n",
    "args.use_colored_prior = False\n",
    "# args.allow_BM_branch = True # Allow separate branch for Brownian motion? (only used when learning decay)\n",
    "args.scale_decay_by_time_interval = True\n",
    "args.zero_rotations = False\n",
    "args.use_ss_process_noise = False\n",
    "args.damping = 0.05\n",
    "\n",
    "args.use_rope = True\n",
    "args.use_alibi = False\n",
    "# args.use_xpos = False\n",
    "\n",
    "args.use_SC_RoPE = False\n",
    "args.use_log_linear_decay = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee497f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ABLATIONS ##\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # BASELINES:\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # B1: Standard Transformer + RoPE Baseline\n",
    "# #     --- Dot-Product Similarity; current SOTA positional encoding baseline.\n",
    "# #     Applies d --> 2d --> d attention projections for fair comparison.\n",
    "# # Uses separate backbone and training looping\n",
    "\n",
    "# ablation_name = 'B1'\n",
    "# args.use_rope = True\n",
    "# args.use_alibi = False\n",
    "# args.use_relative_decay_vanilla = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # B2: Standard Transformer + ALiBi Baseline\n",
    "# #     Applies d --> 2d --> d attention projections for fair comparison.\n",
    "# # Uses separate backbone and training looping\n",
    "\n",
    "# ablation_name = 'B2'\n",
    "# args.use_rope = False\n",
    "# args.use_alibi = True\n",
    "# args.use_relative_decay_vanilla = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # B3 (RoPE + decay):\n",
    "# ablation_name = 'B3'\n",
    "# args.use_rope = True\n",
    "# args.use_alibi = False\n",
    "# args.use_SC_RoPE = False\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.use_relative_decay_vanilla = True\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # B4 (SC-RoPE):\n",
    "# ablation_name = 'B4'\n",
    "# args.use_rope = False\n",
    "# args.use_alibi = False\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.use_relative_decay_vanilla = True\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # MAIN MODELS:\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M1: Isotropic RFA\n",
    "\n",
    "# # Default settings\n",
    "# ablation_name = 'M1'\n",
    "# args.use_log_linear_decay = False\n",
    "# args.damping = 0.05\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # # M1.1: Isotropic RFA w/o DLE Prior\n",
    "\n",
    "# # Default settings\n",
    "# ablation_name = 'M1.1'\n",
    "# args.use_log_linear_decay = False\n",
    "# args.damping = 0.05\n",
    "# args.zero_process_noise = True\n",
    "# args.zero_key_measurement_noise = True\n",
    "# args.additive_bias_type = 0\n",
    "# args.multiplicative_bias_type = 0\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M1.2: Isotropic RFA w/o robust weight\n",
    "\n",
    "# # Default settings\n",
    "# ablation_name = 'M1.2'\n",
    "# args.use_log_linear_decay = False\n",
    "# args.damping = 0.05\n",
    "# args.use_robust_weight = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2: Spectrally-Coupled RFA\n",
    "# # # --- M1, but we partition the angular frequencies so that the fast frequencies\n",
    "# # # are coupled with fast decays and vice versa\n",
    "\n",
    "# ablation_name = 'M2'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.005\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2.1 (M2 + no robust weight)\n",
    "# ablation_name = 'M2.1'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.use_robust_weight = False\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2.2: Spectrally-Coupled RFA, w/o DLE Prior\n",
    "# # # --- M2, but we ablate the DLE\n",
    "\n",
    "# ablation_name = 'M2.2'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.zero_process_noise = True\n",
    "# args.zero_key_measurement_noise = True\n",
    "# args.additive_bias_type = 0\n",
    "# args.multiplicative_bias_type = 0\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# M2.3: (M2 + ablate out only multiplicative gate but keep additive term)\n",
    "\n",
    "# ablation_name = 'M2.3'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.additive_bias_type = 1 # Keep additive term\n",
    "# args.multiplicative_bias_type = 0 # Set multiplicative term to constant\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2.4: (M2 + No Value rotations)\n",
    "\n",
    "# ablation_name = 'M2.4'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.use_log_linear_decay = False\n",
    "# args.rotate_values = False\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2.5: (M2 + No Rotations)\n",
    "# ablation_name = 'M2.5'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.05\n",
    "# args.use_log_linear_decay = False\n",
    "# args.zero_rotations = True\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# # M2.6: (Unitary, zero noise Limit)\n",
    "# ablation_name = 'M2.6'\n",
    "# args.use_SC_RoPE = True\n",
    "# args.scale_decay_by_time_interval = False\n",
    "# args.damping = 0.0\n",
    "# args.use_log_linear_decay = False\n",
    "\n",
    "# args.use_robust_weight = False\n",
    "# args.use_full_residual_norm = 0\n",
    "# args.lambda_real_zero = True\n",
    "# args.zero_process_noise = True\n",
    "# args.zero_key_measurement_noise = True\n",
    "# args.additive_bias_type = 0\n",
    "# args.multiplicative_bias_type = 0\n",
    "# args.max_fixed_decay = 0.0 # Zero out decay\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# M2.7: Spectrally-Coupled RFA + Total Confidence Gate\n",
    "\n",
    "ablation_name = 'M2.7'\n",
    "args.use_SC_RoPE = True\n",
    "args.scale_decay_by_time_interval = False\n",
    "args.damping = 0.05\n",
    "args.use_log_linear_decay = False\n",
    "args.use_inner_residual = True\n",
    "args.use_total_precision_gate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71535f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ablation_name)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ef9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## DEFINE BACKBONE ##\n",
    "#####################\n",
    "\n",
    "###########################################################\n",
    "\n",
    "# # Standard Transformer\n",
    "\n",
    "# args.num_blocks = 6\n",
    "# backbone = TransformerNetwork(args.d_e, args.d_e*2, args.d_e*4, args.n_heads, args, num_blocks=args.num_blocks, Norm=nn.LayerNorm)\n",
    "\n",
    "###########################################################\n",
    "\n",
    "# RFA Transformer\n",
    "\n",
    "args.num_blocks = 6\n",
    "backbone = RFATransformerNetwork(args=args, num_blocks=args.num_blocks, n_heads=args.n_heads, input_dim=args.d_e, query_key_dim_total=args.d_k_total, value_dim_total=args.d_v_total, hidden_dim = 4*args.d_v_total, Norm=nn.LayerNorm)\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526332ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap it to create the Language Model\n",
    "model = LanguageModel(\n",
    "    backbone=backbone, \n",
    "    vocab_size=args.vocab_size, \n",
    "    embed_dim=args.d_e\n",
    ").to(args.device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "params_list = list(model.parameters()) # Parameters list\n",
    "\n",
    "print('Total parameter count:', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the Data Collator\n",
    "# mlm=False is crucial: it tells the collator we are doing Causal LM, \n",
    "# not Masked LM (like BERT). It will ensure labels are handled correctly.\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    lm_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    lm_datasets[\"validation\"],\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    lm_datasets[\"test\"],\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 4. Quick Test of the first batch\n",
    "batch = next(iter(train_dataloader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Labels shape: {batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## TRAINING SETUP ##\n",
    "####################\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Loss\n",
    "\n",
    "args.num_epochs = 15 # Number of epochs\n",
    "\n",
    "args.save_model = True\n",
    "\n",
    "args.save_epochs = 1 # Intervals of epochs to save model\n",
    "args.show_example_epochs = 1 # Number of epochs between displaying results\n",
    "\n",
    "#####################\n",
    "\n",
    "# Create folders for model weights, and loss history\n",
    "\n",
    "try:\n",
    "    root_path = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    root_path = os.getcwd()\n",
    "\n",
    "# saved_models_path = os.path.join(root_path, 'saved_models\\\\wikitext_103\\\\')\n",
    "saved_models_path = os.path.join(root_path, 'saved_models\\\\main_models\\\\')\n",
    "# saved_models_path = os.path.join(root_path, 'saved_models\\\\babylm_2025\\\\')\n",
    "model_name = str(model.backbone.__class__.__name__)\n",
    "date = str(datetime.datetime.today()).split()\n",
    "date_time = date[0]\n",
    "# date_time = date[0] + '_' + date[1][0:5].replace(\":\", \"_\")\n",
    "model_path = saved_models_path + model_name + '__' + ablation_name + '__' + date_time + '\\\\'\n",
    "# model_path = saved_models_path + '__' + ablation_name + '__' + date_time + '\\\\'\n",
    "\n",
    "try:\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "except:\n",
    "    pass\n",
    "# try:\n",
    "#     os.makedirs(model_weight_path, exist_ok=True)\n",
    "# #     os.makedirs(model_tensor_path, exist_ok=True)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "saved_models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c184b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD MODEL ##\n",
    "################\n",
    "\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'TransformerNetwork__B4__2026-01-21')\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'RFATransformerNetwork__M1.2__2026-01-24')\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'RFATransformerNetwork__M4__2026-01-17')\n",
    "checkpoint_path = os.path.join(saved_models_path, 'M2_b0.05')\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'RFATransformerNetwork__M2.7__2026-01-27')\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'M2.3')\n",
    "# checkpoint_path = os.path.join(saved_models_path, 'B1_redo')\n",
    "# \n",
    "# checkpoint_path = os.path.join(checkpoint_path, \"standard_transformer_epoch_15.pt\")\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"afa_lm_epoch_15.pt\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=args.device)\n",
    "    \n",
    "#     ###############\n",
    "# #     Identify the keys that cause the size mismatch (buffers, not weights)\n",
    "# #     We want to keep weights/biases but drop the positional/masking grids\n",
    "#     weights = checkpoint['model_state_dict']\n",
    "\n",
    "#     # Filter out the positional/masking buffers that have the wrong size\n",
    "#     # This keeps the learned weights but lets the model use its new 4096-sized grids\n",
    "#     keys_to_drop = [\n",
    "#         k for k in weights.keys() \n",
    "#         if \"causal_mask\" in k or \"rope.cos\" in k or \"rope.sin\" in k or \"rope.positions\" in k\n",
    "#     ]\n",
    "\n",
    "#     for k in keys_to_drop:\n",
    "#         del weights[k]\n",
    "\n",
    "#     model.load_state_dict(weights, strict=False)\n",
    "#     ###############\n",
    "\n",
    "    # Restore Model Weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Extract History and Test Results\n",
    "    history = checkpoint['history']\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # Print Stored Results\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Resuming from Epoch: {start_epoch}\")\n",
    "    print(f\"Last Val PPL: {history['val_ppl'][-1]:.2f}\")\n",
    "    print('Validation history:', history['val_ppl'])\n",
    "    \n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae737ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Access the omega (frequency) tensor\n",
    "rfa_layer = model.backbone.blocks[0].attn\n",
    "omega = rfa_layer.omega_v \n",
    "\n",
    "# 2. Compare the first and last head\n",
    "head_0 = omega[0]\n",
    "head_last = omega[-1]\n",
    "\n",
    "# 3. Compute the similarity\n",
    "are_identical = torch.equal(head_0, head_last)\n",
    "\n",
    "print(f\"Frequencies across heads are identical: {are_identical}\")\n",
    "\n",
    "if are_identical:\n",
    "    print(\"CRITICAL: You are using Standard RoPE (Wrong for M8).\")\n",
    "else:\n",
    "    print(\"SUCCESS: Your Spectral Coupling is preserved (Right for M8).\")\n",
    "    print(f\"Head 0 Max Freq: {head_0.max().item():.6f}\")\n",
    "    print(f\"Head Last Max Freq: {head_last.max().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transformer_damping(model):\n",
    "    \"\"\"\n",
    "    Scans a Transformer model to find attention layers and \n",
    "    calculate the effective damping ratio 'b'.\n",
    "    \"\"\"\n",
    "    print(f\"{'Block':<8} | {'Type':<15} | {'Avg b':<10} | {'Zero Frac':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Iterate through all modules to find the attention layers\n",
    "    for name, module in model.named_modules():\n",
    "        # Check for Isotropic RFA (M8)\n",
    "        if \"MultiheadIsotropicRFA\" in str(type(module)):\n",
    "            mu = module.mu_v.detach().cpu()\n",
    "            omega = module.omega_v.detach().cpu()\n",
    "            \n",
    "            # Max omega for each head's shard is at the end: omega[:, -1]\n",
    "            max_omegas = omega[:, -1]\n",
    "            mask = mu > 0\n",
    "            \n",
    "            avg_b = (mu[mask] / max_omegas[mask]).mean().item() if mask.any() else 0.0\n",
    "            zero_frac = (mu == 0).float().mean().item()\n",
    "            \n",
    "            print(f\"{name:<8} | RFA (M8)       | {avg_b:.4f}     | {zero_frac:.2f}\")\n",
    "\n",
    "        # Check for Heuristic Attention (M14)\n",
    "        elif \"SpectralCoupledHeuristicAttention\" in str(type(module)):\n",
    "            mu = module.mu.detach().cpu()\n",
    "            # Frequencies are stored in the SCRoPE or RoPE sub-module\n",
    "            omega = module.rope.theta.detach().cpu()\n",
    "            \n",
    "            # Handle standard RoPE (1D theta) vs SCRoPE (2D theta)\n",
    "            if omega.ndim == 1:\n",
    "                max_omega = omega[-1]\n",
    "                mask = mu > 0\n",
    "                avg_b = (mu[mask] / max_omega).mean().item() if mask.any() else 0.0\n",
    "            else:\n",
    "                max_omegas = omega[:, -1]\n",
    "                mask = mu > 0\n",
    "                avg_b = (mu[mask] / max_omegas[mask]).mean().item() if mask.any() else 0.0\n",
    "                \n",
    "            zero_frac = (mu == 0).float().mean().item()\n",
    "            print(f\"{name:<8} | Heuristic (M14)| {avg_b:.4f}     | {zero_frac:.2f}\")\n",
    "\n",
    "# Usage:\n",
    "check_transformer_damping(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babaaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training complete. Performing final evaluation on Test Set...\")\n",
    "model.eval()\n",
    "\n",
    "# 1. Use 'sum' reduction to get total negative log-likelihood\n",
    "total_loss = 0.0\n",
    "total_tokens = 0\n",
    "criterion_sum = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
    "        logits, _ = model(batch[\"input_ids\"], t_measure=None, causal=True)\n",
    "        \n",
    "        # Shift logic\n",
    "        shift_logits = logits[:, :-1, :].contiguous()\n",
    "        shift_labels = batch[\"labels\"][:, 1:].contiguous()\n",
    "        \n",
    "        # 2. Identify non-padding tokens (ignore_index assumes -100 or your pad_id)\n",
    "        # If your labels use a specific pad_id, replace -100 with that id.\n",
    "        mask = (shift_labels != -100) \n",
    "        num_tokens = mask.sum().item()\n",
    "        \n",
    "        # 3. Calculate sum of losses for this batch\n",
    "        loss_sum = criterion_sum(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)), \n",
    "            shift_labels.view(-1)\n",
    "        )\n",
    "        \n",
    "        total_loss += loss_sum.item()\n",
    "        total_tokens += num_tokens\n",
    "\n",
    "# 4. PPL: exp( (sum of all losses) / (total tokens) )\n",
    "avg_nll = total_loss / total_tokens\n",
    "test_ppl = np.exp(avg_nll)\n",
    "\n",
    "history['test_loss'] = avg_nll # This is the average loss per token\n",
    "history['test_ppl'] = test_ppl\n",
    "\n",
    "print(f\"Final Test Results | Avg NLL: {avg_nll:.4f} | PPL: {test_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e35843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_rfa_lm(model, val_dataset, history, epoch, folder, args,\n",
    "                    save=False,\n",
    "                    plot_log_losses_flag=True,\n",
    "                    plot_last_attn_mat_flag=True,\n",
    "                    plot_decay_per_iteration=True,\n",
    "                    plot_noise_params=True,\n",
    "                    plot_tau_and_nu_flag=True):\n",
    "    \"\"\"\n",
    "    Plots RFA dynamics with colorblind-safe, professional styling.\n",
    "    Enforces specific physiological limits for SDE parameters.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # --- Colorblind-Friendly Palette (Okabe-Ito inspired) ---\n",
    "    cb_colors = [\n",
    "        '#0072B2', # Deep Blue\n",
    "        '#E69F00', # Orange\n",
    "        '#CC79A7', # Soft Magenta\n",
    "        '#56B4E9', # Sky Blue\n",
    "        '#F0E442', # Yellow\n",
    "        '#000000', # Black\n",
    "        '#D55E00', # Vermillion\n",
    "        '#999999'  # Gray\n",
    "    ]\n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.size\": 11,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"legend.fontsize\": 9,\n",
    "        \"grid.alpha\": 0.2,\n",
    "        \"grid.linestyle\": \"-\"\n",
    "    })\n",
    "\n",
    "    # --- Data Preparation ---\n",
    "    history_data = {k: np.array(v) for k, v in history.items()}\n",
    "\n",
    "    def plot_heads(data, ylabel, filename, is_memory_floor=False, is_alpha=False, \n",
    "                   y_limit=None, pad=0.05, start_head=0):\n",
    "        \"\"\"\n",
    "        Plots a subset of heads with specific damping/noise limits.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        \n",
    "        # Determine the range of heads to plot\n",
    "        # For the \"last 6\", we start at index 2 (assuming 8 heads total)\n",
    "        for h in range(start_head, args.n_heads):\n",
    "            # Additional safety for specific Bayesian plots\n",
    "            if (is_memory_floor or is_alpha) and h < 2: \n",
    "                continue\n",
    "                \n",
    "            y = data[:, h]\n",
    "            plt.plot(y, color=cb_colors[h % len(cb_colors)], label=f'Head {h+1}', \n",
    "                     linewidth=1.2, alpha=0.9)\n",
    "\n",
    "        if y_limit is not None:\n",
    "            y_min, y_max = y_limit\n",
    "            y_range = y_max - y_min\n",
    "            plt.ylim(y_min - y_range * pad, y_max + y_range * pad)\n",
    "\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        if save:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            plt.savefig(os.path.join(folder, f'{filename}_epoch_{epoch}.pdf'), \n",
    "                        bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        rand_idx = np.random.choice(len(val_dataset))\n",
    "        raw_item = val_dataset[rand_idx]\n",
    "        \n",
    "        item = raw_item['input_ids'] if isinstance(raw_item, dict) else raw_item\n",
    "        if not isinstance(item, torch.Tensor):\n",
    "            item = torch.tensor(item)\n",
    "            \n",
    "        inputs = item.unsqueeze(0).to(args.device)\n",
    "        _, output_dict = model(inputs, t_measure=None, causal=True)\n",
    "        attn_mat = output_dict.get('attn_mat', None)\n",
    "        \n",
    "        # --- 1. Log Loss Plot ---\n",
    "        if plot_log_losses_flag:\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            losses = np.log(history_data['loss'])\n",
    "            plt.plot(losses, color=cb_colors[0], alpha=0.15, label='Log Iter Loss')\n",
    "            if len(losses) > 100:\n",
    "                smooth = np.convolve(losses, np.ones(100)/100, mode='valid')\n",
    "                plt.plot(smooth, color='#000000', linewidth=1.5, label='Moving Avg')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('log(Loss)')\n",
    "            plt.legend(loc='upper right', frameon=False)\n",
    "            plt.grid(True)\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(folder, f'log_loss_epoch_{epoch}.pdf'), bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # --- 2. Attention Matrices ---\n",
    "        if plot_last_attn_mat_flag and attn_mat is not None:\n",
    "             n_heads = attn_mat.size(1)\n",
    "             fig, axes = plt.subplots(1, n_heads, figsize=(n_heads * 4, 4))\n",
    "             if n_heads == 1: axes = [axes]\n",
    "             for h in range(n_heads):\n",
    "                 A = attn_mat[0, h].cpu().numpy()\n",
    "                 axes[h].imshow(A**0.25, cmap='magma') \n",
    "                 axes[h].set_axis_off()\n",
    "                 axes[h].set_title(f\"H{h}\", fontsize=10)\n",
    "             plt.tight_layout()\n",
    "             plt.show() \n",
    "             plt.close()\n",
    "\n",
    "        # --- 3. Learned Decay Tracking ---\n",
    "        if plot_decay_per_iteration:\n",
    "             plot_heads(history_data['mu'], r\"Damping Rate ($\\mu$)\", 'decay_evolution')\n",
    "\n",
    "        # --- 4. Noise Params ---\n",
    "        if plot_noise_params:\n",
    "            # Key Noise: eta^2 (Limit: 0.8 - 1.9)\n",
    "            plot_heads(history_data['eta'], r'$\\eta^2$ (Key Noise)', 'eta_sq', \n",
    "                       y_limit=(0.8, 2.0))\n",
    "            \n",
    "            # Query Noise: gamma^2 (Limit: 0.8 - 1.6)\n",
    "            plot_heads(history_data['gamma'], r'$\\gamma^2$ (Query Noise)', 'gamma_sq', \n",
    "                       y_limit=(0.7, 1.6))\n",
    "            \n",
    "            # Process Noise: sigma^2\n",
    "            plot_heads(history_data['sigma'], r'$\\sigma^2$ (Process Noise)', 'sigma_sq', y_limit=(0.0, 0.01))\n",
    "            \n",
    "            # Steady state process noise: Sigma^2 / 2Mu (Limit: 0.05 - 0.11)\n",
    "            mu = history_data['mu']\n",
    "            sigma = history_data['sigma']\n",
    "            floor = sigma / (2 * mu + 1e-10)\n",
    "            plot_heads(floor, r'Steady state process noise ($\\sigma^2/2\\mu$)', 'memory_floor', \n",
    "                       is_memory_floor=True, y_limit=(0.05, 0.11))\n",
    "\n",
    "            # Phase Transition Parameter (Alpha) (Limit: 0.75 - 2.0)\n",
    "            eta = history_data['eta']\n",
    "            alpha = eta - floor\n",
    "            plot_heads(alpha, r'Phase Parameter ($\\alpha$)', 'alpha_phase', \n",
    "                       is_alpha=True)\n",
    "\n",
    "#             # --- Noise Ratio: Process / (Key + Query) ---\n",
    "#             floor = sigma / (2 * mu + 1e-10)\n",
    "#             # Noise Ratio: Process / (Key + Query)\n",
    "#             # Use np.divide to handle array-wise division safely\n",
    "#             noise_ratio = np.divide(sigma, (eta + history_data['gamma'] + 1e-10))\n",
    "#             plot_heads(noise_ratio, r'Noise Ratio [$\\sigma^2 / (\\eta^2 + \\gamma^2)$]', \n",
    "#                'noise_ratio_evolution', y_limit=(0.1, 0.5), start_head=2)\n",
    "            \n",
    "#             print(eta.size())\n",
    "        \n",
    "        # --- 5. Tau and Nu Tracking ---\n",
    "        if plot_tau_and_nu_flag:\n",
    "            # Inverse Temp: tau (Limit: 1.3 - 2.6)\n",
    "            plot_heads(history_data['tau'], r'Inv. Temp ($\\tau$)', 'tau_tracking', \n",
    "                       y_limit=(1.3, 2.6))\n",
    "            \n",
    "            # Robustness: nu/d (Limit: 4.0 - 5.75)\n",
    "            plot_heads(history_data['nu_over_d'], r'Robustness ($\\nu/d$)', 'nu_tracking', \n",
    "                       y_limit=(4.0, 5.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_progress_lm(history, 15, checkpoint_path, save=False)\n",
    "\n",
    "visualize_rfa_lm(model, eval_dataloader.dataset, history, 15, checkpoint_path, args,\n",
    "                    save=False,\n",
    "                    plot_log_losses_flag=True,\n",
    "                    plot_last_attn_mat_flag=True,\n",
    "                    plot_decay_per_iteration=True,\n",
    "                    plot_noise_params = True,\n",
    "                    plot_tau_and_nu_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77a0d3",
   "metadata": {},
   "source": [
    "### Extrapolation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251845cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.arange(8)+1)*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your extrapolation length (e.g., 512, 1024, 2048, or 4096)\n",
    "extrapolation_block_size = 1024\n",
    "\n",
    "# Map the tokenized data to the new, larger block size\n",
    "extrapolation_dataset = tokenized_datasets[\"test\"].map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    fn_kwargs={\"block_size\": extrapolation_block_size}\n",
    ")\n",
    "\n",
    "print(f\"Extrapolation Dataset size: {len(extrapolation_dataset)} blocks\")\n",
    "print(f\"New Sequence Length: {len(extrapolation_dataset[0]['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Set batch_size=1 to avoid OOM on long sequences\n",
    "extrapolation_dataloader = DataLoader(\n",
    "    extrapolation_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# 4. Verification check\n",
    "test_batch = next(iter(extrapolation_dataloader))\n",
    "print(f\"Extrapolation Batch Input Shape: {test_batch['input_ids'].shape}\") # Should be [1, 2048]\n",
    "print(f\"Extrapolation Batch Labels Shape: {test_batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Performing Extrapolation Evaluation (Length: {extrapolation_block_size})...\")\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "total_tokens = 0\n",
    "criterion_sum = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(extrapolation_dataloader):\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items()}\n",
    "        logits, _ = model(batch[\"input_ids\"], t_measure=None, causal=True)\n",
    "        \n",
    "        shift_logits = logits[:, :-1, :].contiguous()\n",
    "        shift_labels = batch[\"labels\"][:, 1:].contiguous()\n",
    "        \n",
    "        mask = (shift_labels != -100) \n",
    "        num_tokens = mask.sum().item()\n",
    "        \n",
    "        loss_sum = criterion_sum(\n",
    "            shift_logits.view(-1, shift_logits.size(-1)), \n",
    "            shift_labels.view(-1)\n",
    "        )\n",
    "        \n",
    "        total_loss += loss_sum.item()\n",
    "        total_tokens += num_tokens\n",
    "\n",
    "avg_nll = total_loss / total_tokens\n",
    "extrap_ppl = np.exp(avg_nll)\n",
    "\n",
    "print(f\"Extrapolation Results ({extrapolation_block_size}) | Avg NLL: {avg_nll:.4f} | PPL: {extrap_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = saved_models_path + \"extrapolation_results.csv\"\n",
    "\n",
    "# Data to save\n",
    "row = {\n",
    "    \"ablation_name\": ablation_name,\n",
    "    \"block_size\": extrapolation_block_size,\n",
    "    \"avg_nll\": f\"{avg_nll:.4f}\",\n",
    "    \"ppl\": f\"{extrap_ppl:.2f}\"\n",
    "}\n",
    "\n",
    "file_exists = os.path.isfile(results_file)\n",
    "\n",
    "with open(results_file, mode='a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "    if not file_exists:\n",
    "        writer.writeheader()  # Write header only once\n",
    "    writer.writerow(row)\n",
    "\n",
    "print(f\"Results appended to {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# # Clear variables from previous loops\n",
    "# del logits\n",
    "# del batch\n",
    "# gc.collect()\n",
    "\n",
    "# # Empty the PyTorch cache\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da990679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extrapolation_results(csv_path):\n",
    "    # 1. Load the data\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {csv_path} not found.\")\n",
    "        return\n",
    "\n",
    "    # 2. Clean and Filter data\n",
    "    df['block_size'] = pd.to_numeric(df['block_size'])\n",
    "    df['ppl'] = pd.to_numeric(df['ppl'])\n",
    "    \n",
    "    # Define your specific target lengths\n",
    "    target_lengths = [512, 1024, 2048, 4096]\n",
    "    \n",
    "    # Filter for only those lengths and valid PPLs (ignoring the 51k crash)\n",
    "    df = df[df['block_size'].isin(target_lengths)]\n",
    "    df = df[df['ppl'] < 500] \n",
    "    \n",
    "    # Average duplicates\n",
    "    df = df.groupby(['ablation_name', 'block_size'])['ppl'].mean().reset_index()\n",
    "    \n",
    "    # 3. Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for i, name in enumerate(df['ablation_name'].unique()):\n",
    "        subset = df[df['ablation_name'] == name].sort_values('block_size')\n",
    "        plt.plot(subset['block_size'], subset['ppl'], \n",
    "                 marker='o', markersize=8, \n",
    "                 label=name, linewidth=2.5, \n",
    "                 color=colors[i % len(colors)])\n",
    "        print(subset['ppl'])\n",
    "    \n",
    "    # 5. Aesthetic formatting\n",
    "    plt.title(\"Perplexity Extrapolation: RFA vs. Baseline\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Context Length (Tokens)\", fontsize=12)\n",
    "    plt.ylabel(\"Perplexity (PPL)\", fontsize=12)\n",
    "    plt.xticks(target_lengths) # Force x-axis to show your exact points\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # 6. Dynamic Y-Axis Framing\n",
    "    # Find the max PPL in your filtered set to set a reasonable ceiling\n",
    "    if not df.empty:\n",
    "        ymax = df['ppl'].max()\n",
    "        ymin = df['ppl'].min()\n",
    "        plt.ylim(ymin - 2, ymax + 5) \n",
    "\n",
    "    plt.legend(frameon=True, loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"extrapolation_results.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "plot_extrapolation_results(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129583c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extrapolation_percentage(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['block_size'] = pd.to_numeric(df['block_size'])\n",
    "    df['ppl'] = pd.to_numeric(df['ppl'])\n",
    "    \n",
    "    # Filter for your specific points and clean\n",
    "    target_lengths = [512, 1024, 1536, 2048, 2560, 3072, 3584, 4096]\n",
    "    df = df[df['block_size'].isin(target_lengths) & (df['ppl'] < 200)]\n",
    "    df = df.groupby(['ablation_name', 'block_size'])['ppl'].mean().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = {'M0_Baseline': '#1f77b4', 'M1_RFA': '#ff7f0e'}\n",
    "\n",
    "    for name in df['ablation_name'].unique():\n",
    "        subset = df[df['ablation_name'] == name].sort_values('block_size')\n",
    "        \n",
    "        # Calculate Percentage Increase relative to length 512\n",
    "        base_ppl = subset[subset['block_size'] == 512]['ppl'].values[0]\n",
    "        subset['pct_increase'] = ((subset['ppl'] - base_ppl) / base_ppl) * 100\n",
    "        \n",
    "        plt.plot(subset['block_size'], subset['pct_increase'], \n",
    "                 marker='o', markersize=8, label=f\"{name} (% Increase)\", \n",
    "                 linewidth=2.5, color=colors.get(name, None))\n",
    "\n",
    "    plt.title(\"Extrapolation Penalty: RFA vs. RoPE\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Context Length (Tokens)\", fontsize=12)\n",
    "    plt.ylabel(\"% Increase in Perplexity (Lower is Better)\", fontsize=12)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"extrapolation_pct_increase.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_extrapolation_percentage(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_advantage(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 1. Ensure numeric types to avoid calculation errors\n",
    "    df['block_size'] = pd.to_numeric(df['block_size'])\n",
    "    df['ppl'] = pd.to_numeric(df['ppl'])\n",
    "\n",
    "    # 2. Pivot carefully. \n",
    "    # NOTE: Use the exact strings in your 'ablation_name' column (e.g., 'M0' and 'M1')\n",
    "    pivot_df = df.pivot_table(index='block_size', columns='ablation_name', values='ppl')\n",
    "    \n",
    "    # 3. Drop any lengths where one model is missing (avoids NaNs/Infs)\n",
    "    pivot_df = pivot_df.dropna(subset=['M0', 'M1'])\n",
    "\n",
    "    # 4. Calculate Improvement\n",
    "    pivot_df['improvement'] = ((pivot_df['M0'] - pivot_df['M1']) / pivot_df['M0']) * 100\n",
    "    \n",
    "    # 5. Clean up any non-finite values before plotting\n",
    "    pivot_df = pivot_df[np.isfinite(pivot_df['improvement'])]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Use .index and .values explicitly to avoid indexing confusion\n",
    "    plt.plot(pivot_df.index.values, pivot_df['improvement'].values, \n",
    "             marker='s', color='green', linewidth=2.5)\n",
    "    \n",
    "    print(pivot_df['improvement'].values)\n",
    "    \n",
    "    plt.title(\"RFA Advantage over RoPE as Context Grows\", fontsize=14)\n",
    "    plt.xlabel(\"Sequence Length\", fontsize=12)\n",
    "    plt.ylabel(\"% Reduction in Perplexity\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Updated labeling loop\n",
    "    for x, y in zip(pivot_df.index.values, pivot_df['improvement'].values):\n",
    "        # If y is positive, put label above. If negative, put label below.\n",
    "        offset = 0.3 if y >= 0 else -0.5\n",
    "        plt.text(x, y + offset, f\"{y:.1f}%\", \n",
    "                 ha='center', fontsize=15, fontweight='bold',\n",
    "                 color='black' if y >= 0 else 'red')\n",
    "\n",
    "    # Add a horizontal line at 0 to show the \"Win/Loss\" boundary\n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.8)\n",
    "\n",
    "    plt.ylim((-1, 7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_relative_advantage(results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efec840",
   "metadata": {},
   "source": [
    "RFA exhibits Length-Dependent Efficiency. While performing competitively within the training horizon, it achieves a 5.5x increase in relative advantage (from 1.1% to 6.2%) as the context window expands to 8x, suggesting that stochastic blurring is a more robust prior for long-range dependencies than rigid positional rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "lengths = [512, 1024, 2048, 4096]\n",
    "data = {\n",
    "    'RoPE (B1)': [28.48, 30.94, 44.21, 72.69],\n",
    "    'ALiBi (B2)': [28.59, 27.30, 26.54, 26.30],\n",
    "    'RFA (M1)': [28.01, 27.58, 29.99, 38.46],\n",
    "    'SC-RFA (M2)': [27.54, 26.73, 29.46, 37.19] \n",
    "}\n",
    "\n",
    "# Colorblind-Friendly Palette (Okabe-Ito)\n",
    "cb_colors = ['#E69F00', '#CC79A7', '#56B4E9', '#0072B2']\n",
    "# Distinctive line styles\n",
    "line_styles = ['--', '-', '-.', ':']\n",
    "# Distinctive markers\n",
    "markers = ['o', 's', '^', 'D']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Sort keys by final value (at 4096) in descending order (highest loss first)\n",
    "sorted_keys = sorted(data.keys(), key=lambda k: data[k][-1], reverse=True)\n",
    "\n",
    "for i, key in enumerate(sorted_keys):\n",
    "    plt.plot(lengths, data[key], \n",
    "             label=f\"{key} ({data[key][-1]:.2f})\", \n",
    "             color=cb_colors[i % len(cb_colors)], \n",
    "             linestyle=line_styles[i % len(line_styles)],\n",
    "             marker=markers[i % len(markers)],\n",
    "             linewidth=2.5, \n",
    "             markersize=10,\n",
    "             markeredgecolor='white', # Adds a \"pop\" to markers\n",
    "             markeredgewidth=1.0)\n",
    "\n",
    "\n",
    "# --- Publication Quality Formatting ---\n",
    "plt.xlabel('Context Length (Tokens)', fontsize=16, labelpad=10)\n",
    "plt.ylabel('Validation Perplexity', fontsize=16, labelpad=10)\n",
    "plt.xticks(lengths, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Use a clean, semi-transparent legend inside the empty top-left space\n",
    "plt.legend(\n",
    "    loc='upper left', \n",
    "    fontsize=13, \n",
    "    frameon=True, \n",
    "    fancybox=True, \n",
    "    shadow=False, \n",
    "    framealpha=0.9, \n",
    "    edgecolor='lightgray',\n",
    "    labelspacing=0.6\n",
    ")\n",
    "\n",
    "# Subtle grid for reference without clutter\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "\n",
    "# Remove the top and right spines for a modern, clean look\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as PDF for vector graphics (essential for LaTeX)\n",
    "plt.savefig('rfa_extrapolation_professional.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981707b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "lengths = [512, 1024, 2048, 4096]\n",
    "data = {\n",
    "    r'$\\mu = 5 \\times 10^{-4}$': [27.60, 28.88, 37.34, 51.48],\n",
    "    r'$\\mu = 5 \\times 10^{-3}$': [0, 0, 0, 0],\n",
    "    r'$\\mu = 5 \\times 10^{-2}$': [27.54, 26.73, 29.46, 37.19],\n",
    "    r'$\\mu = 5 \\times 10^{-1}$': [27.61, 26.38, 26.37, 29.72],\n",
    "    r'$\\mu = 5 \\times 10^{0}$': [27.91, 26.68, 26.37, 28.16],\n",
    "    'ALiBi (B2)': [28.64, 27.31, 26.55, 26.31]\n",
    "}\n",
    "\n",
    "# --- Explicit Legend Order (Manual override) ---\n",
    "ordered_keys = [\n",
    "    r'$\\mu = 5 \\times 10^{-4}$',\n",
    "    r'$\\mu = 5 \\times 10^{-3}$',\n",
    "    r'$\\mu = 5 \\times 10^{-2}$',\n",
    "    r'$\\mu = 5 \\times 10^{-1}$',\n",
    "    r'$\\mu = 5 \\times 10^{0}$',\n",
    "    'ALiBi (B2)'\n",
    "]\n",
    "\n",
    "# Expanded Okabe-Ito Palette (6 colors)\n",
    "cb_colors = ['#0072B2', '#E69F00', '#CC79A7', '#56B4E9', '#009E73', '#D55E00']\n",
    "line_styles = ['-.', '-', '--', '-', (0, (3, 5, 1, 5)), (0, (5, 10))] \n",
    "markers = ['o', 's', '^', 'D', 'v', 'p']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, key in enumerate(ordered_keys):\n",
    "    plt.plot(lengths, data[key], \n",
    "             label=f\"{key} ({data[key][-1]:.2f})\", \n",
    "             color=cb_colors[i], \n",
    "             linestyle=line_styles[i],\n",
    "             marker=markers[i],\n",
    "             linewidth=3.0, \n",
    "             markersize=10,\n",
    "             markeredgecolor='white', \n",
    "             markeredgewidth=1.5)\n",
    "\n",
    "# --- Publication Quality Formatting ---\n",
    "plt.xlabel('Context Length (Tokens)', fontsize=16, labelpad=10)\n",
    "plt.ylabel('Validation Perplexity', fontsize=16, labelpad=10)\n",
    "\n",
    "# Focusing the view on the active data range\n",
    "plt.ylim(20, 55) \n",
    "\n",
    "plt.xticks(lengths, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Legend Configuration\n",
    "plt.legend(\n",
    "    loc='upper left', \n",
    "    fontsize=12, \n",
    "    frameon=True, \n",
    "    fancybox=True, \n",
    "    framealpha=0.9, \n",
    "    edgecolor='lightgray',\n",
    "    labelspacing=0.5\n",
    ")\n",
    "\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "\n",
    "# Remove the top and right spines for a clean look\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rfa_ablation_ordered_final.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c046bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from Table: Sensitivity Analysis of the Damping Factor b in SC-RFA (M2)\n",
    "b_values = [5e-4, 5e-3, 5e-2, 5e-1, 5e0]\n",
    "b_labels = [r'$5 \\times 10^{-4}$', r'$5 \\times 10^{-3}$', r'$5 \\times 10^{-2}$', r'$5 \\times 10^{-1}$', r'$5 \\times 10^{0}$']\n",
    "\n",
    "# Transpose table data: each list represents a fixed context window L\n",
    "data_512 = [27.60, 27.60, 27.54, 27.61, 27.91]\n",
    "data_1024 = [28.88, 28.71, 26.73, 26.38, 26.68]\n",
    "data_2048 = [37.34, 35.35, 29.46, 26.37, 26.37]\n",
    "data_4096 = [51.48, 43.90, 37.19, 29.72, 28.16]\n",
    "\n",
    "lengths_data = {\n",
    "    'L = 512': data_512,\n",
    "    'L = 1024': data_1024,\n",
    "    'L = 2048': data_2048,\n",
    "    'L = 4096': data_4096\n",
    "}\n",
    "\n",
    "ordered_keys = ['L = 512', 'L = 1024', 'L = 2048', 'L = 4096']\n",
    "\n",
    "# Okabe-Ito Palette and styles\n",
    "cb_colors = ['#0072B2', '#E69F00', '#CC79A7', '#009E73']\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "markers = ['o', 's', '^', 'D']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, key in enumerate(ordered_keys):\n",
    "    plt.plot(b_values, lengths_data[key], \n",
    "             label=f\"${key}$\", \n",
    "             color=cb_colors[i], \n",
    "             linestyle=line_styles[i],\n",
    "             marker=markers[i],\n",
    "             linewidth=3.0, \n",
    "             markersize=10,\n",
    "             markeredgecolor='white', \n",
    "             markeredgewidth=1.5)\n",
    "\n",
    "# Publication Quality Formatting\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Damping Factor $b$', fontsize=16, labelpad=10)\n",
    "plt.ylabel('Validation Perplexity', fontsize=16, labelpad=10)\n",
    "\n",
    "plt.xticks(b_values, b_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Focusing view range\n",
    "plt.ylim(25, 55)\n",
    "\n",
    "plt.legend(\n",
    "    loc='upper right', \n",
    "    fontsize=12, \n",
    "    frameon=True, \n",
    "    fancybox=True, \n",
    "    framealpha=0.9, \n",
    "    edgecolor='lightgray',\n",
    "    labelspacing=0.5,\n",
    "    title='Context Length'\n",
    ")\n",
    "plt.setp(plt.gca().get_legend().get_title(), fontsize='14')\n",
    "\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "\n",
    "# Clean spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rfa_b_sensitivity_fixed_windows.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69372c44",
   "metadata": {},
   "source": [
    "### Plot attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5540f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Input\n",
    "sample = extrapolation_dataset[0]\n",
    "input_ids = torch.tensor(sample['input_ids']).unsqueeze(0).to(args.device)\n",
    "L_total = input_ids.shape[1]\n",
    "L_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the \"nuke\" option for Matplotlib settings\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If using standard attention:\n",
    "    \n",
    "# # Forward Pass: Standard Model (M0)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     _, returned_data_std = model(input_ids, return_attn=True)\n",
    "\n",
    "# attentions = returned_data_std if isinstance(returned_data_std, list) else returned_data_std.get('attn_mat')\n",
    "\n",
    "# from matplotlib.colors import PowerNorm\n",
    "\n",
    "# def plot_final_layer_heads_standard(attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=False):\n",
    "#     # Extract sequence limits\n",
    "#     start, end = view_range\n",
    "    \n",
    "#     # Handle both list-of-layers and single-tensor formats\n",
    "#     if isinstance(attentions, list) or isinstance(attentions, tuple):\n",
    "#         layer_attn = attentions[layer_idx][0]\n",
    "#     else:\n",
    "#         # Assuming [B, L, L, H] -> [H, L, L] for batch 0\n",
    "#         layer_attn = attentions.permute(0, 3, 1, 2)[0] if attentions.ndim == 4 else attentions\n",
    "\n",
    "#     num_heads = layer_attn.shape[0]\n",
    "#     fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     for i in range(num_heads):\n",
    "#         matrix = layer_attn[i].cpu().detach().numpy()\n",
    "        \n",
    "#         # Scaling Logic\n",
    "#         if use_powernorm:\n",
    "#             # PowerNorm helps reveal long-range \"ghost\" signals in the baseline\n",
    "#             norm = PowerNorm(gamma=0.2)\n",
    "#             im = axes[i].imshow(matrix, cmap='magma', norm=norm)\n",
    "#         else:\n",
    "#             # Standard linear scaling clipped at 99.5th percentile\n",
    "#             vmax = np.percentile(matrix, 99.5)\n",
    "#             im = axes[i].imshow(matrix, cmap='magma', vmin=0, vmax=vmax)\n",
    "        \n",
    "#         # Apply the dynamic view range\n",
    "#         axes[i].set_xlim(start, end)\n",
    "#         axes[i].set_ylim(end, start)\n",
    "#         axes[i].set_title(f\"Head {i+1}\", fontsize=28)\n",
    "#         axes[i].axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     scale_type = \"Power\" if use_powernorm else \"Linear\"\n",
    "#     plt.suptitle(f\"Standard Transformer (M0): {scale_type} Scale | Range {start}-{end}\", fontsize=20, y=1.05)\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "# # Example usage:\n",
    "# # plot_final_layer_heads_standard(attentions, view_range=(3000, 4096), use_powernorm=True)\n",
    "\n",
    "# # Example: Global View\n",
    "# plot_final_layer_heads_standard(attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=False)\n",
    "# # Example: Extrapolation Zoom\n",
    "# plot_final_layer_heads_standard(attentions, layer_idx=-1, view_range=(3000, 4096), use_powernorm=False)\n",
    "\n",
    "# # Example: Global View\n",
    "# plot_final_layer_heads_standard(attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=True)\n",
    "# # Example: Extrapolation Zoom\n",
    "# plot_final_layer_heads_standard(attentions, layer_idx=-1, view_range=(3000, 4096), use_powernorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using RFA models:\n",
    "\n",
    "model.eval()\n",
    "model.backbone.args.compute_metadata = True\n",
    "model.backbone.args.compute_pulled_forward_estimates = False\n",
    "with torch.no_grad():\n",
    "    _, output_dict_rfa = model(input_ids, causal=True)\n",
    "\n",
    "# Extract attention matrices\n",
    "attentions = output_dict_rfa['attn_mat']\n",
    "\n",
    "from matplotlib.colors import PowerNorm\n",
    "\n",
    "def plot_rfa_final_layer(model, attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=False):\n",
    "    \"\"\"\n",
    "    Standardized plotting for RFA heads with optional PowerNorm.\n",
    "    \"\"\"\n",
    "    start, end = view_range\n",
    "    \n",
    "    # Extract attention [H, L, L] for the first batch\n",
    "    A = attentions.permute(0, 3, 1, 2)[0]\n",
    "    rfa_module = model.backbone.blocks[layer_idx].attn\n",
    "\n",
    "    # Physical Constants\n",
    "    seq_len_train = model.backbone.args.seq_len\n",
    "    scale_r = model.backbone.args.max_fixed_decay / (seq_len_train - 1)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(22, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(A.shape[0]):\n",
    "        matrix = A[i].cpu().numpy()\n",
    "        \n",
    "        # Scaling Logic\n",
    "        if use_powernorm:\n",
    "            # Amplifies faint signals (good for seeing the diffusive 'haze')\n",
    "            norm = PowerNorm(gamma=0.2)\n",
    "            im = axes[i].imshow(matrix, cmap='magma', norm=norm)\n",
    "        else:\n",
    "            # Linear scale clipped at 99.5th percentile (good for seeing actual density)\n",
    "            vmax = np.percentile(matrix, 99.5)\n",
    "            im = axes[i].imshow(matrix, cmap='magma', vmin=0, vmax=vmax)\n",
    "        \n",
    "        # Physics Metrics\n",
    "        actual_mu = scale_r * rfa_module.mu_v[i].item()\n",
    "        mu_L = actual_mu * end \n",
    "        survival = np.exp(-mu_L) * 100\n",
    "\n",
    "        axes[i].set_xlim(start, end)\n",
    "        axes[i].set_ylim(end, start)\n",
    "        axes[i].set_title(f\"Head {i+1}\\nÎ¼L: {mu_L:.2f}\\nSurv: {survival:.1f}%\", fontsize=22)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"RFA Transformer (M1): {'Power' if use_powernorm else 'Linear'} Scale\", fontsize=24, y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "# Run the analysis\n",
    "# Global View\n",
    "plot_rfa_final_layer(model, attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=False)\n",
    "# Extrapolation Zoom\n",
    "plot_rfa_final_layer(model, attentions, layer_idx=-1, view_range=(3000, 4096), use_powernorm=False)\n",
    "\n",
    "# Global View\n",
    "plot_rfa_final_layer(model, attentions, layer_idx=-1, view_range=(0, 4096), use_powernorm=True)\n",
    "# Extrapolation Zoom\n",
    "plot_rfa_final_layer(model, attentions, layer_idx=-1, view_range=(3000, 4096), use_powernorm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3040a",
   "metadata": {},
   "source": [
    "The visual contrast between the Standard Transformer (M0) and the RFA Transformer (M1) provides a direct explanation for the modelâ€™s performance stability during long-context extrapolation. In the M0 linear plots, a pervasive \"checkerboard\" noise is visible across almost every head, characterized by faint, chaotic activations across the entire history. This indicates that the Standard Transformer is wasting significant attention mass on distant tokens it can no longer geometrically resolve, directly contributing to the observed perplexity explosion.\n",
    "\n",
    "In contrast, the M1 linear plots demonstrate that the \"shutting off\" of certain heads is a deliberate form of geometric regularization. The RFA model establishes a clear functional hierarchy:\n",
    "* Global Anchors (Heads 1 and 2): With a decay of $\\mu L = 0.00$, these heads maintain $100\\%$ survival. They provide the model with a stable long-range memory that remains clear because it is no longer drowned out by the noise of the other six heads.\n",
    "* Ultra-Local Specialists (Heads 7 and 8): These high-decay heads focus exclusively on the most recent context, visible as a sharp diagonal. By effectively ignoring the distant past, they eliminate the \"noise floor\" that plagues the standard model.\n",
    "* Denoising through Specialization: While the first five heads eventually shut off after a certain context length, this represents an intelligent trade-off. Even when memory remains high, the accumulation of Brownian noise makes distant signals unreliable. By refusing to attend to these areas of high uncertainty, these heads effectively denoise the model.\n",
    "\n",
    "The Standard Transformer fails in extrapolation because every head attempts to \"do everything at every distance,\" leading to chaotic interference. RFA succeeds by enforcing a multi-resolution hierarchy where specialized heads prioritize signal over noise, resulting in a cleaner, more periodic attention structure that drives the 6% perplexity win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9751d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.args.compute_metadata = True\n",
    "model.backbone.args.add_gaussian_noise = True\n",
    "model.backbone.args.compute_pulled_forward_estimates = False\n",
    "\n",
    "def autoregressive_sample(model, start_seq, max_gen_len, t_measure=None, t_shift=None, t_equal=True, causal=True):\n",
    "    \"\"\"\n",
    "    Performs discrete autoregressive generation and collects SDE precision metadata.\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # current_seq shape: [B, L] (Integers/Token IDs)\n",
    "        current_seq = start_seq \n",
    "        total_seq = start_seq\n",
    "        window_size = start_seq.size(1)\n",
    "\n",
    "        for i in tqdm(range(max_gen_len), desc=\"Generating tokens\"):\n",
    "            # Forward pass: out contains the logits for the whole sequence\n",
    "            out, output_dict = model(current_seq, t_measure=t_measure, t_shift=t_shift, causal=causal) \n",
    "\n",
    "            # Capture Precision for visualization\n",
    "            p_step = torch.mean(output_dict['P_tot'][:, -1, :], dim=-1) \n",
    "            precisions.append(p_step)\n",
    "\n",
    "            # 1. Convert logits to Token ID (Argmax)\n",
    "            # out[:, -1, :] is the vocabulary distribution for the latest step\n",
    "            next_token_id = torch.argmax(out[:, -1, :], dim=-1).unsqueeze(1) # Shape: [B, 1]\n",
    "\n",
    "            # 2. Append the ID to the sequence\n",
    "            total_seq = torch.cat([total_seq, next_token_id], dim=1)\n",
    "            \n",
    "            # 3. Slide the window to maintain context length\n",
    "            current_seq = total_seq[:, -window_size:]\n",
    "\n",
    "    # Extract only the newly generated IDs\n",
    "    new_seq = total_seq[:, -max_gen_len:]\n",
    "\n",
    "    return total_seq, new_seq, precisions\n",
    "\n",
    "def plot_text_precision_heatmap(token_ids, precisions, tokenizer):\n",
    "    \"\"\"\n",
    "    Overlays text with background colors representing SDE precision.\n",
    "    precisions: normalized precision array [gen_len]\n",
    "    token_ids: list of token IDs [gen_len]\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    # Ensure precision is 1D and normalized\n",
    "    p = precisions.flatten() \n",
    "    tokens = [tokenizer.decode([tid]) for tid in token_ids]\n",
    "    \n",
    "    # Generate HTML with background colors (using the Viridis scale)\n",
    "    # We map 0.0 -> Purple/Dark and 1.0 -> Yellow/Bright\n",
    "    html_output = '<div style=\"line-height: 2.0; font-family: monospace;\">'\n",
    "    \n",
    "    for token, score in zip(tokens, p):\n",
    "        # Calculate color intensity (using a simple yellow/green scale for trust)\n",
    "        # alpha is the precision score\n",
    "        color = f\"rgba(255, 0, 0, {score:.3f})\" # Yellow highlight\n",
    "        \n",
    "        # Alternatively, a red-to-green scale\n",
    "        # color = f\"rgb({int(255*(1-score))}, {int(255*score)}, 100)\"\n",
    "        \n",
    "        html_output += f'<span style=\"background-color: {color}; padding: 2px; margin: 1px; border-radius: 3px;\" title=\"P_tot: {score:.2f}\">{token}</span>'\n",
    "    \n",
    "    html_output += '</div>'\n",
    "    display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.args.compute_metadata=True\n",
    "model.backbone.args.add_gaussian_noise = True\n",
    "\n",
    "# 1. Get a starting sequence from the test set\n",
    "# [1, 512]\n",
    "idx=6\n",
    "sample_input = torch.tensor(extrapolation_dataset[idx]['input_ids'][:args.seq_len]).unsqueeze(0).to(args.device)\n",
    "\n",
    "# 2. Generate 100 new tokens\n",
    "total_ids, new_ids, p_list = autoregressive_sample(\n",
    "    model, \n",
    "    sample_input, \n",
    "    max_gen_len=100, \n",
    "    t_equal=args.t_equal, \n",
    "    causal=args.causal\n",
    ")\n",
    "\n",
    "# 3. Process Precisions\n",
    "p_tensor = torch.stack(p_list, dim=1).squeeze(0) # [100]\n",
    "p_min, p_max = p_tensor.min(), p_tensor.max()\n",
    "p_normalized = (p_tensor - p_min) / (p_max - p_min + 1e-8)\n",
    "\n",
    "# 4. Show the result\n",
    "print(\"\\n--- GENERATED TEXT WITH SDE PRECISION OVERLAY ---\")\n",
    "# Convert new_ids to list for the plotting function\n",
    "plot_text_precision_heatmap(new_ids.squeeze(0).cpu().tolist(), p_normalized.cpu().numpy(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_sequence_precision(model, input_ids, args):\n",
    "    \"\"\"\n",
    "    Scans a ground-truth sequence and returns the precision for each token.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass on the full sequence\n",
    "        # input_ids shape: [1, seq_len]\n",
    "        logits, output_dict = model(input_ids, t_measure=None, causal=True)\n",
    "        \n",
    "        # P_tot shape is [B, L, H]\n",
    "        # We take the mean across heads to get a global 'confidence' per token\n",
    "        p_seq = torch.mean(output_dict['P_tot'], dim=-1).squeeze(0) # [seq_len]\n",
    "        \n",
    "        # Normalize for visualization\n",
    "        p_min, p_max = p_seq.min(), p_seq.max()\n",
    "        p_norm = (p_seq - p_min) / (p_max - p_min + 1e-8)\n",
    "        \n",
    "    return p_norm.cpu().numpy()\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Take a 100-token slice to make the visualization readable\n",
    "sample_ids = torch.tensor(extrapolation_dataset[0]['input_ids'][:100]).unsqueeze(0).to(args.device)\n",
    "p_map = scan_sequence_precision(model, sample_ids, args)\n",
    "\n",
    "# Use your red intensity function\n",
    "print(\"\\n--- GROUND TRUTH PRECISION SCAN ---\")\n",
    "plot_text_precision_heatmap(sample_ids.squeeze(0).cpu().tolist(), p_map, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d53ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_sliding_window_scan(model, full_ids, window_size=512, scan_len=100):\n",
    "    \"\"\"\n",
    "    Performs a sliding window scan to ensure every token is evaluated \n",
    "    with a full 'Warm' context window.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    warm_precisions = []\n",
    "    target_tokens = []\n",
    "    \n",
    "    # We scan the last 'scan_len' tokens of the sequence\n",
    "    start_idx = full_ids.size(1) - scan_len\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(start_idx, full_ids.size(1)), desc=\"Sliding Window Scan\"):\n",
    "            # Extract the 512 tokens leading up to the current token i\n",
    "            # Context is [i - window_size : i]\n",
    "            # Current token is at index i\n",
    "            context_window = full_ids[:, i - window_size : i + 1] \n",
    "            \n",
    "            # Forward pass on the window\n",
    "            _, output_dict = model(context_window.to(args.device), causal=True)\n",
    "            \n",
    "            # Extract precision for the very last token (the one at index i)\n",
    "            # P_tot shape: [B, L, H]. We take [:, -1, :]\n",
    "            p_step = torch.mean(output_dict['P_tot'][:, -1, :], dim=-1) # [B]\n",
    "            warm_precisions.append(p_step)\n",
    "            target_tokens.append(full_ids[0, i].item())\n",
    "            \n",
    "    # Normalize for the heatmap\n",
    "    p_tensor = torch.stack(warm_precisions).squeeze() # [scan_len]\n",
    "    p_min, p_max = p_tensor.min(), p_tensor.max()\n",
    "    p_norm = (p_tensor - p_min) / (p_max - p_min + 1e-8)\n",
    "    \n",
    "    return target_tokens, p_norm.cpu().numpy()\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Use the large extrapolation block (size 4096)\n",
    "# We take a slice large enough to provide 512 context for a 100-token scan\n",
    "full_block_ids = torch.tensor(extrapolation_dataset[2]['input_ids']).unsqueeze(0)\n",
    "tokens, p_map = warm_sliding_window_scan(model, full_block_ids, window_size=512, scan_len=100)\n",
    "\n",
    "print(\"\\n--- WARM SLIDING WINDOW SCAN (512 Context) ---\")\n",
    "plot_text_precision_heatmap(tokens, p_map, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00877555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbbed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
